{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKING_DIR = '.' #os.path.dirname(__file__)\n",
    "DATA_DIR = os.path.join(WORKING_DIR, 'data', 'hillary-clinton-emails')\n",
    "EMAILS_FILE = os.path.join(DATA_DIR, 'Emails.csv')\n",
    "EMAILS_RECEIVERS_FILE = os.path.join(DATA_DIR, 'EmailReceivers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-B\n",
    "Загрузите датасет с kaggle: https://www.kaggle.com/kaggle/hillary-clinton-emails\n",
    "Изучите, из чего состоит датасет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aliases.csv** - список контактов Хиллари Клинтон\n",
    "\n",
    "**EmailReceivers.csv** - соответствие писем и отправителей\n",
    "\n",
    "**Emails.csv** - текст письма и его характеристики\n",
    "\n",
    "**Persons.csv** - имена отправителей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n",
    "Предобработайте тексты как сочтете правильным для первых экспериментов. Опишите, как вы его предобрабатываете, и почему так в блокноте в markdown ячейке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, что в любом письме важны в первую очередь получатель, отправитель. Поэтому возьмем их в качестве признаков вместе с текстами. (Заголовки пригодятся ниже для анализа.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    df_emails = pd.read_csv(EMAILS_FILE, sep=',', encoding='utf-8')\n",
    "    df_emails_receivers = pd.read_csv(EMAILS_RECEIVERS_FILE, sep=',', encoding='utf-8')\n",
    "    # Чистим пропуски\n",
    "    df_emails = df_emails.dropna(subset=['SenderPersonId','ExtractedBodyText','ExtractedSubject'])\n",
    "    receivers = []\n",
    "    for id in df_emails.Id:\n",
    "        ids = df_emails_receivers.loc[df_emails_receivers.EmailId == id].PersonId.values\n",
    "        if len(ids) == 0:\n",
    "            receivers.append(-1)\n",
    "        else:\n",
    "            receivers.append(ids[0])\n",
    "    return pd.DataFrame({\n",
    "            'sender': list(map(int, df_emails.SenderPersonId)),\n",
    "            'receiver': receivers,\n",
    "            'subject': df_emails.ExtractedSubject,\n",
    "            'text': df_emails.ExtractedBodyText\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>receiver</th>\n",
       "      <th>sender</th>\n",
       "      <th>subject</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228</td>\n",
       "      <td>32</td>\n",
       "      <td>Re: Chris Stevens</td>\n",
       "      <td>Thx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>185</td>\n",
       "      <td>80</td>\n",
       "      <td>Meet The Right Wing Extremist Behind Anti-Musl...</td>\n",
       "      <td>Pis print.\\n-•-...-^\\nH &lt; hrod17@clintonernail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>FVV: Secretary's remarks</td>\n",
       "      <td>FYI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>AbZ and Hb3 on Libya and West Bank/Gaza</td>\n",
       "      <td>Fyi\\nB6\\n— —</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>hey</td>\n",
       "      <td>Fyi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    receiver  sender                                            subject  \\\n",
       "2        228      32                                  Re: Chris Stevens   \n",
       "5        185      80  Meet The Right Wing Extremist Behind Anti-Musl...   \n",
       "8         80      87                           FVV: Secretary's remarks   \n",
       "10        80      87            AbZ and Hb3 on Libya and West Bank/Gaza   \n",
       "12        80      87                                                hey   \n",
       "\n",
       "                                                 text  \n",
       "2                                                 Thx  \n",
       "5   Pis print.\\n-•-...-^\\nH < hrod17@clintonernail...  \n",
       "8                                                 FYI  \n",
       "10                                       Fyi\\nB6\\n— —  \n",
       "12                                                Fyi  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного пофильтруем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>receiver</th>\n",
       "      <th>sender</th>\n",
       "      <th>subject</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228</td>\n",
       "      <td>32</td>\n",
       "      <td>Re: Chris Stevens</td>\n",
       "      <td>Thx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>185</td>\n",
       "      <td>80</td>\n",
       "      <td>Meet The Right Wing Extremist Behind Anti-Musl...</td>\n",
       "      <td>Pis print           H   hrod17 clintonernailco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>FVV: Secretary's remarks</td>\n",
       "      <td>FYI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>AbZ and Hb3 on Libya and West Bank/Gaza</td>\n",
       "      <td>Fyi B6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>hey</td>\n",
       "      <td>Fyi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    receiver  sender                                            subject  \\\n",
       "2        228      32                                  Re: Chris Stevens   \n",
       "5        185      80  Meet The Right Wing Extremist Behind Anti-Musl...   \n",
       "8         80      87                           FVV: Secretary's remarks   \n",
       "10        80      87            AbZ and Hb3 on Libya and West Bank/Gaza   \n",
       "12        80      87                                                hey   \n",
       "\n",
       "                                                 text  \n",
       "2                                                 Thx  \n",
       "5   Pis print           H   hrod17 clintonernailco...  \n",
       "8                                                 FYI  \n",
       "10                                         Fyi B6      \n",
       "12                                                Fyi  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "df.text = [re.sub('[^a-zA-Z0-9]', ' ', text) for text in df.text]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D\n",
    "Выясните, какие биграммы чаще всего встречаются в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('york times', 442),\n",
       " ('york ny', 441),\n",
       " ('york new', 440),\n",
       " ('years ago', 439),\n",
       " ('year old', 438),\n",
       " ('xpress mail', 437),\n",
       " ('world war', 436),\n",
       " ('women issues', 435),\n",
       " ('white house', 434),\n",
       " ('west bank', 433)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2,2), stop_words = 'english', min_df = 10).fit(df.text)\n",
    "sorted(bigram_vectorizer.vocabulary_.items(), key=operator.itemgetter(1), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E\n",
    "Попробуйте выделить коллокации из двух слов по PMI с помощью nltk (примеры можно найти по ссылке: http://www.nltk.org/howto/collocations.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_text = ' '.join(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('029', 'mo'),\n",
       " ('ABOUL', 'GHEIT'),\n",
       " ('Appointment', 'Affidavit'),\n",
       " ('Buenos', 'Aires'),\n",
       " ('CHIEF', 'NEGOTIATOR'),\n",
       " ('Cardinal', 'Stadium'),\n",
       " ('Ensuring', 'Connections'),\n",
       " ('Fixed', 'LendingTree'),\n",
       " ('GUIDO', 'WESTERWELLE'),\n",
       " ('JASSIM', 'JABR')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.collocations\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "bgm = nltk.collocations.BigramAssocMeasures()\n",
    "finder = nltk.collocations.BigramCollocationFinder.from_words(word_tokenize(joined_text))\n",
    "finder.apply_freq_filter(3)\n",
    "finder.nbest(bgm.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F + H\n",
    "Выполните любую несложную кластеризацию писем (не тратьте на этот шаг много времени)\n",
    "Поработайте с признаками и методом кластеризации так, чтобы кластеры выглядели наиболее интерпретируемыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df_raw):\n",
    "    X_raw = TfidfVectorizer(max_df=500, min_df=10).fit_transform(df_raw.text)\n",
    "    X_raw = np.hstack((X_raw.toarray(), df.sender.values.reshape(X_raw.shape[0],1)))\n",
    "    X_raw =  np.hstack((X_raw, df.receiver.values.reshape(X_raw.shape[0],1)))\n",
    "    return X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5414, 3133)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = extract_features(df)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "CLUSTERS_COUNT = 6\n",
    "\n",
    "model = model = KMeans(n_clusters=CLUSTERS_COUNT, random_state=1)\n",
    "preds = model.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G\n",
    "Придумайте, как визуализировать содержание кластеров. Например, можно выводить самые частые слова из каждого кластера (но, вероятно, это не самая удачная идея). Визуализируйте ту кластеризацию, которая у вас уже получилась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_preds = df.copy()\n",
    "df_preds['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2931 291 656 1066 371 99'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([str(df_preds[df_preds.preds == i].shape[0]) for i in range(CLUSTERS_COUNT)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(zwire, 10306)</td>\n",
       "      <td>(zi, 2118)</td>\n",
       "      <td>(zx, 16244)</td>\n",
       "      <td>(zzity, 7766)</td>\n",
       "      <td>(zia, 2259)</td>\n",
       "      <td>(zurich, 1040)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(zuma, 10305)</td>\n",
       "      <td>(zealand, 2117)</td>\n",
       "      <td>(zumbi, 16243)</td>\n",
       "      <td>(zone, 7765)</td>\n",
       "      <td>(zelaya, 2258)</td>\n",
       "      <td>(youth, 1039)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(zuckerman, 10304)</td>\n",
       "      <td>(younger, 2116)</td>\n",
       "      <td>(zuma, 16242)</td>\n",
       "      <td>(zipping, 7764)</td>\n",
       "      <td>(youths, 2257)</td>\n",
       "      <td>(young, 1038)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(zones, 10303)</td>\n",
       "      <td>(young, 2115)</td>\n",
       "      <td>(zulciernain, 16241)</td>\n",
       "      <td>(zevon, 7763)</td>\n",
       "      <td>(youth, 2256)</td>\n",
       "      <td>(yes, 1037)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(zone, 10302)</td>\n",
       "      <td>(yesterday, 2114)</td>\n",
       "      <td>(zones, 16240)</td>\n",
       "      <td>(zeleya, 7762)</td>\n",
       "      <td>(younger, 2255)</td>\n",
       "      <td>(years, 1036)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(zintan, 10301)</td>\n",
       "      <td>(yes, 2113)</td>\n",
       "      <td>(zone, 16239)</td>\n",
       "      <td>(zela, 7761)</td>\n",
       "      <td>(york, 2254)</td>\n",
       "      <td>(year, 1035)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(zimbabwean, 10300)</td>\n",
       "      <td>(years, 2112)</td>\n",
       "      <td>(zobmbz, 16238)</td>\n",
       "      <td>(zein, 7760)</td>\n",
       "      <td>(yonight, 2253)</td>\n",
       "      <td>(yang, 1034)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(zia, 10299)</td>\n",
       "      <td>(year, 2111)</td>\n",
       "      <td>(ziyang, 16237)</td>\n",
       "      <td>(zealand, 7759)</td>\n",
       "      <td>(yohannes, 2252)</td>\n",
       "      <td>(wsjournal, 1033)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(zhu, 10298)</td>\n",
       "      <td>(yeah, 2110)</td>\n",
       "      <td>(zionists, 16236)</td>\n",
       "      <td>(zartman, 7758)</td>\n",
       "      <td>(yesterday, 2251)</td>\n",
       "      <td>(wrote, 1032)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(zhou, 10297)</td>\n",
       "      <td>(xmas, 2109)</td>\n",
       "      <td>(zionist, 16235)</td>\n",
       "      <td>(yuval, 7757)</td>\n",
       "      <td>(yesss, 2250)</td>\n",
       "      <td>(wrong, 1031)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                  1                     2  \\\n",
       "0       (zwire, 10306)         (zi, 2118)           (zx, 16244)   \n",
       "1        (zuma, 10305)    (zealand, 2117)        (zumbi, 16243)   \n",
       "2   (zuckerman, 10304)    (younger, 2116)         (zuma, 16242)   \n",
       "3       (zones, 10303)      (young, 2115)  (zulciernain, 16241)   \n",
       "4        (zone, 10302)  (yesterday, 2114)        (zones, 16240)   \n",
       "5      (zintan, 10301)        (yes, 2113)         (zone, 16239)   \n",
       "6  (zimbabwean, 10300)      (years, 2112)       (zobmbz, 16238)   \n",
       "7         (zia, 10299)       (year, 2111)       (ziyang, 16237)   \n",
       "8         (zhu, 10298)       (yeah, 2110)     (zionists, 16236)   \n",
       "9        (zhou, 10297)       (xmas, 2109)      (zionist, 16235)   \n",
       "\n",
       "                 3                  4                  5  \n",
       "0    (zzity, 7766)        (zia, 2259)     (zurich, 1040)  \n",
       "1     (zone, 7765)     (zelaya, 2258)      (youth, 1039)  \n",
       "2  (zipping, 7764)     (youths, 2257)      (young, 1038)  \n",
       "3    (zevon, 7763)      (youth, 2256)        (yes, 1037)  \n",
       "4   (zeleya, 7762)    (younger, 2255)      (years, 1036)  \n",
       "5     (zela, 7761)       (york, 2254)       (year, 1035)  \n",
       "6     (zein, 7760)    (yonight, 2253)       (yang, 1034)  \n",
       "7  (zealand, 7759)   (yohannes, 2252)  (wsjournal, 1033)  \n",
       "8  (zartman, 7758)  (yesterday, 2251)      (wrote, 1032)  \n",
       "9    (yuval, 7757)      (yesss, 2250)      (wrong, 1031)  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_dict = dict()\n",
    "for i in range(CLUSTERS_COUNT):\n",
    "    unigram_vectorizer = CountVectorizer(stop_words = 'english').fit(df_preds[df_preds.preds == i].text)\n",
    "    word_counts = sorted(unigram_vectorizer.vocabulary_.items(), key=operator.itemgetter(1), reverse=True)[:10]\n",
    "    top_dict[i] = word_counts\n",
    "df_top = pd.DataFrame(top_dict)\n",
    "df_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(zwire com, 46192)</td>\n",
       "      <td>(zi a79, 4094)</td>\n",
       "      <td>(zx htmi, 83688)</td>\n",
       "      <td>(zzity ii, 25042)</td>\n",
       "      <td>(zia use, 4357)</td>\n",
       "      <td>(zurich lisle, 1614)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(zuma making, 46191)</td>\n",
       "      <td>(zealand pacific, 4093)</td>\n",
       "      <td>(zumbi dos, 83687)</td>\n",
       "      <td>(zone years, 25041)</td>\n",
       "      <td>(zelaya people, 4356)</td>\n",
       "      <td>(youth behavior, 1613)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(zuma jibril, 46190)</td>\n",
       "      <td>(younger brother, 4092)</td>\n",
       "      <td>(zuma add, 83686)</td>\n",
       "      <td>(zone north, 25040)</td>\n",
       "      <td>(youths treat, 4355)</td>\n",
       "      <td>(young abused, 1612)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(zuckerman ed, 46189)</td>\n",
       "      <td>(young woman, 4091)</td>\n",
       "      <td>(zulciernain tahir, 83685)</td>\n",
       "      <td>(zone authorized, 25039)</td>\n",
       "      <td>(youths times, 4354)</td>\n",
       "      <td>(yes stephens, 1611)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(zuckerman dinner, 46188)</td>\n",
       "      <td>(yesterday young, 4090)</td>\n",
       "      <td>(zones schools, 83684)</td>\n",
       "      <td>(zipping state, 25038)</td>\n",
       "      <td>(youths detained, 4353)</td>\n",
       "      <td>(years happened, 1610)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(zones aware, 46187)</td>\n",
       "      <td>(yesterday second, 4089)</td>\n",
       "      <td>(zone weeks, 83683)</td>\n",
       "      <td>(zevon wonderful, 25037)</td>\n",
       "      <td>(youths color, 4352)</td>\n",
       "      <td>(years earlier, 1609)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(zone taken, 46186)</td>\n",
       "      <td>(yesterday process, 4088)</td>\n",
       "      <td>(zone suicide, 83682)</td>\n",
       "      <td>(zeleya unpersuadable, 25036)</td>\n",
       "      <td>(youth won, 4351)</td>\n",
       "      <td>(years case, 1608)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(zone support, 46185)</td>\n",
       "      <td>(yesterday internal, 4087)</td>\n",
       "      <td>(zone security, 83681)</td>\n",
       "      <td>(zeleya going, 25035)</td>\n",
       "      <td>(youth rehabilitation, 4350)</td>\n",
       "      <td>(years ann, 1607)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(zone region, 46184)</td>\n",
       "      <td>(yesterday effective, 4086)</td>\n",
       "      <td>(zone said, 83680)</td>\n",
       "      <td>(zeleya appeared, 25034)</td>\n",
       "      <td>(youth happen, 4349)</td>\n",
       "      <td>(year scoresheet, 1606)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(zone libya, 46183)</td>\n",
       "      <td>(yes ii, 4085)</td>\n",
       "      <td>(zone possible, 83679)</td>\n",
       "      <td>(zela bar, 25033)</td>\n",
       "      <td>(youth development, 4348)</td>\n",
       "      <td>(year looking, 1605)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                            1  \\\n",
       "0         (zwire com, 46192)               (zi a79, 4094)   \n",
       "1       (zuma making, 46191)      (zealand pacific, 4093)   \n",
       "2       (zuma jibril, 46190)      (younger brother, 4092)   \n",
       "3      (zuckerman ed, 46189)          (young woman, 4091)   \n",
       "4  (zuckerman dinner, 46188)      (yesterday young, 4090)   \n",
       "5       (zones aware, 46187)     (yesterday second, 4089)   \n",
       "6        (zone taken, 46186)    (yesterday process, 4088)   \n",
       "7      (zone support, 46185)   (yesterday internal, 4087)   \n",
       "8       (zone region, 46184)  (yesterday effective, 4086)   \n",
       "9        (zone libya, 46183)               (yes ii, 4085)   \n",
       "\n",
       "                            2                              3  \\\n",
       "0            (zx htmi, 83688)              (zzity ii, 25042)   \n",
       "1          (zumbi dos, 83687)            (zone years, 25041)   \n",
       "2           (zuma add, 83686)            (zone north, 25040)   \n",
       "3  (zulciernain tahir, 83685)       (zone authorized, 25039)   \n",
       "4      (zones schools, 83684)         (zipping state, 25038)   \n",
       "5         (zone weeks, 83683)       (zevon wonderful, 25037)   \n",
       "6       (zone suicide, 83682)  (zeleya unpersuadable, 25036)   \n",
       "7      (zone security, 83681)          (zeleya going, 25035)   \n",
       "8          (zone said, 83680)       (zeleya appeared, 25034)   \n",
       "9      (zone possible, 83679)              (zela bar, 25033)   \n",
       "\n",
       "                              4                        5  \n",
       "0               (zia use, 4357)     (zurich lisle, 1614)  \n",
       "1         (zelaya people, 4356)   (youth behavior, 1613)  \n",
       "2          (youths treat, 4355)     (young abused, 1612)  \n",
       "3          (youths times, 4354)     (yes stephens, 1611)  \n",
       "4       (youths detained, 4353)   (years happened, 1610)  \n",
       "5          (youths color, 4352)    (years earlier, 1609)  \n",
       "6             (youth won, 4351)       (years case, 1608)  \n",
       "7  (youth rehabilitation, 4350)        (years ann, 1607)  \n",
       "8          (youth happen, 4349)  (year scoresheet, 1606)  \n",
       "9     (youth development, 4348)     (year looking, 1605)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_dict = dict()\n",
    "for i in range(CLUSTERS_COUNT):\n",
    "    bigram_vectorizer = CountVectorizer(ngram_range=(2,2), stop_words = 'english').fit(df_preds[df_preds.preds == i].text)\n",
    "    word_counts = sorted(bigram_vectorizer.vocabulary_.items(), key=operator.itemgetter(1), reverse=True)[:10]\n",
    "    top_dict[i] = word_counts\n",
    "df_top = pd.DataFrame(top_dict)\n",
    "df_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на заголовки писем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(zuckerman, 2017)</td>\n",
       "      <td>(zelaya, 484)</td>\n",
       "      <td>(zak, 894)</td>\n",
       "      <td>(zones, 1590)</td>\n",
       "      <td>(zones, 709)</td>\n",
       "      <td>(zealand, 175)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(zest, 2016)</td>\n",
       "      <td>(youknow, 483)</td>\n",
       "      <td>(youth, 893)</td>\n",
       "      <td>(zelikow, 1589)</td>\n",
       "      <td>(yohannes, 708)</td>\n",
       "      <td>(year, 174)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(zelaya, 2015)</td>\n",
       "      <td>(yoga, 482)</td>\n",
       "      <td>(youknow, 892)</td>\n",
       "      <td>(zelaya, 1588)</td>\n",
       "      <td>(year, 707)</td>\n",
       "      <td>(yeah, 173)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(zebari, 2014)</td>\n",
       "      <td>(year, 481)</td>\n",
       "      <td>(year, 891)</td>\n",
       "      <td>(youtube, 1587)</td>\n",
       "      <td>(www, 706)</td>\n",
       "      <td>(ye, 172)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(zardari, 2013)</td>\n",
       "      <td>(xmas, 480)</td>\n",
       "      <td>(xmas, 890)</td>\n",
       "      <td>(young, 1586)</td>\n",
       "      <td>(wsj, 705)</td>\n",
       "      <td>(yang, 171)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(zach, 2012)</td>\n",
       "      <td>(wpost, 479)</td>\n",
       "      <td>(wyden, 889)</td>\n",
       "      <td>(yohannes, 1585)</td>\n",
       "      <td>(wrong, 704)</td>\n",
       "      <td>(xo, 170)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(yu, 2011)</td>\n",
       "      <td>(work, 478)</td>\n",
       "      <td>(wsj, 888)</td>\n",
       "      <td>(yesterday, 1584)</td>\n",
       "      <td>(wpost, 703)</td>\n",
       "      <td>(world, 169)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(young, 2010)</td>\n",
       "      <td>(wjc, 477)</td>\n",
       "      <td>(wpost, 887)</td>\n",
       "      <td>(yeo, 1583)</td>\n",
       "      <td>(worst, 702)</td>\n",
       "      <td>(wjc, 168)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(york, 2009)</td>\n",
       "      <td>(wishing, 476)</td>\n",
       "      <td>(world, 886)</td>\n",
       "      <td>(year, 1582)</td>\n",
       "      <td>(world, 701)</td>\n",
       "      <td>(views, 167)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(ynet, 2008)</td>\n",
       "      <td>(wing, 475)</td>\n",
       "      <td>(workers, 885)</td>\n",
       "      <td>(yaryura, 1581)</td>\n",
       "      <td>(work, 700)</td>\n",
       "      <td>(video, 166)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0               1               2                  3  \\\n",
       "0  (zuckerman, 2017)   (zelaya, 484)      (zak, 894)      (zones, 1590)   \n",
       "1       (zest, 2016)  (youknow, 483)    (youth, 893)    (zelikow, 1589)   \n",
       "2     (zelaya, 2015)     (yoga, 482)  (youknow, 892)     (zelaya, 1588)   \n",
       "3     (zebari, 2014)     (year, 481)     (year, 891)    (youtube, 1587)   \n",
       "4    (zardari, 2013)     (xmas, 480)     (xmas, 890)      (young, 1586)   \n",
       "5       (zach, 2012)    (wpost, 479)    (wyden, 889)   (yohannes, 1585)   \n",
       "6         (yu, 2011)     (work, 478)      (wsj, 888)  (yesterday, 1584)   \n",
       "7      (young, 2010)      (wjc, 477)    (wpost, 887)        (yeo, 1583)   \n",
       "8       (york, 2009)  (wishing, 476)    (world, 886)       (year, 1582)   \n",
       "9       (ynet, 2008)     (wing, 475)  (workers, 885)    (yaryura, 1581)   \n",
       "\n",
       "                 4               5  \n",
       "0     (zones, 709)  (zealand, 175)  \n",
       "1  (yohannes, 708)     (year, 174)  \n",
       "2      (year, 707)     (yeah, 173)  \n",
       "3       (www, 706)       (ye, 172)  \n",
       "4       (wsj, 705)     (yang, 171)  \n",
       "5     (wrong, 704)       (xo, 170)  \n",
       "6     (wpost, 703)    (world, 169)  \n",
       "7     (worst, 702)      (wjc, 168)  \n",
       "8     (world, 701)    (views, 167)  \n",
       "9      (work, 700)    (video, 166)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_dict = dict()\n",
    "for i in range(CLUSTERS_COUNT):\n",
    "    unigram_vectorizer = CountVectorizer(stop_words = 'english').fit(df_preds[df_preds.preds == i].subject)\n",
    "    word_counts = sorted(unigram_vectorizer.vocabulary_.items(), key=operator.itemgetter(1), reverse=True)[:10]\n",
    "    top_dict[i] = word_counts\n",
    "df_top = pd.DataFrame(top_dict)\n",
    "df_top"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORKING_DIR = '.' #os.path.dirname(__file__)\n",
    "DATA_DIR = os.path.join(WORKING_DIR, 'data', 'smsspamcollection')\n",
    "DATA_FILE = os.path.join(DATA_DIR, 'SMSSpamCollection.txt')\n",
    "\n",
    "CLASS = 'class'\n",
    "TEXT = 'text'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - 3\n",
    "\n",
    "Загрузите датасет по ссылке:\n",
    "http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/smsspamcollection.zip\n",
    "\n",
    "Считайте датасет в Python (можете сразу грузить все в память, выборка\n",
    "небольшая), выясните, что используется в качестве разделителей и как\n",
    "проставляются метки классов.\n",
    "\n",
    "Подготовьте для дальнейшей работы два списка: список текстов в порядке\n",
    "их следования в датасете и список соответствующих им меток классов.\n",
    "В качестве метки класса используйте 1 для спама и 0 для \"не спама\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    content = pd.read_csv(filename, sep='\\t', encoding='utf-8', names=[CLASS, TEXT])\n",
    "    labels = content[CLASS] != 'ham'\n",
    "    return content, content[TEXT].values, labels.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, texts, y = get_data(DATA_FILE)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "Используя sklearn.feature_extraction.text.CountVectorizer со стандартными\n",
    "настройками, получите из списка текстов матрицу признаков X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8713)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_vectorizer = CountVectorizer()\n",
    "X = default_vectorizer.fit_transform(texts)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5\n",
    "\n",
    "Оцените качество классификации текстов с помощью LogisticRegression() с\n",
    "параметрами по умолчанию, используя\n",
    "sklearn.cross_validation.cross_val_score и посчитав среднее\n",
    "арифметическое качества на отдельных fold'ах. Параметр cv задайте\n",
    "равным 10. В качестве метрики качества используйте f1-меру.\n",
    "Получившееся качество – ответ в этом пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_SPLITS = 10\n",
    "SCORING = 'f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(clf, X, y, n_splits, scoring):\n",
    "    scores = cross_val_score(clf, X, y, cv=n_splits, scoring=scoring, n_jobs=-1)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score: 0.932640298361\n"
     ]
    }
   ],
   "source": [
    "print('Mean f1 score:', test_classifier(LogisticRegression(), X, y, N_SPLITS, SCORING))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "А теперь обучите классификатор на всей выборке и спрогнозируйте с его\n",
    "помощью класс для следующих сообщений:\n",
    "\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use\n",
    "from your phone now! Subscribe6GB\"\n",
    "\"FreeMsg: Txt: claim your reward of 3 hours talk time\"\n",
    "\"Have you visited the last lecture on physics?\"\n",
    "\"Have you visited the last lecture on physics? Just buy this book and you will have\n",
    "all materials! Only 99\\$\"\n",
    "\"Only 99\\$\"\n",
    "Выпишите через пробел прогнозы классификатора (0 – не спам, 1 – спам)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_TEXT = [\n",
    "    'FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB',\n",
    "    'FreeMsg: Txt: claim your reward of 3 hours talk time',\n",
    "    'Have you visited the last lecture on physics?',\n",
    "    'Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$',\n",
    "    'Only 99$'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8713)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = default_vectorizer.transform(TEST_TEXT)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0 0 0\n"
     ]
    }
   ],
   "source": [
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(X, y)\n",
    "y_pred = clf_lr.predict(X_test)\n",
    "print(' '.join(y_pred.astype('str')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\n",
    "Задайте в CountVectorizer параметр ngram_range=(2,2), затем\n",
    "ngram_range=(3,3), затем ngram_range=(1,3). Во всех трех случаях\n",
    "измерьте получившееся в кросс-валидации значение f1-меры,\n",
    "округлите до второго знака после точки, и выпишете результаты через\n",
    "пробел в том же порядке. В данном эксперименте мы пробовали\n",
    "добавлять в признаки n-граммы для разных диапазонов n - только\n",
    "биграммы, только триграммы, и, наконец, все вместе - униграммы,\n",
    "биграммы и триграммы. Обратите внимание, что статистики по\n",
    "биграммам и триграммам намного меньше, поэтому классификатор\n",
    "только на них работает хуже. В то же время это не ухудшает результат\n",
    "сколько-нибудь существенно, если добавлять их вместе с\n",
    "униграммами, т.к. за счет регуляризации линейный классификатор не\n",
    "склонен сильно переобучаться на этих признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VECTORIZERS = [\n",
    "    CountVectorizer(ngram_range=(2,2)),\n",
    "    CountVectorizer(ngram_range=(3,3)),\n",
    "    CountVectorizer(ngram_range=(1,3))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_vectorizers(vectorizers, texts_raw, y_raw, clf, n_splits, scoring):\n",
    "    scores = []\n",
    "    for v in vectorizers:\n",
    "        X_temp = v.fit_transform(texts_raw)\n",
    "        scores.append(test_classifier(clf, X_temp, y_raw, n_splits, scoring))\n",
    "    return np.array(scores).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82 0.73 0.93\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(test_vectorizers(\n",
    "            VECTORIZERS, texts, y, LogisticRegression(), N_SPLITS, SCORING).astype('str')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8\n",
    "Повторите аналогичный п.7 эксперимент, используя вместо логистической регрессии MultinomialNB(). Обратите внимание, насколько сильнее (по сравнению с линейным классификатором) наивный Байес страдает от нехватки статистики по биграммам и триграммам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.38 0.89\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(test_vectorizers(\n",
    "            VECTORIZERS, texts, y, MultinomialNB(), N_SPLITS, SCORING).astype('str')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9\n",
    "Попробуйте использовать в логистической регрессии в качестве признаков Tf\\*idf из TfidfVectorizer на униграммах. Повысилось или понизилось качество на кросс-валидации по сравнению с CountVectorizer на униграммах? Обратите внимание, что результат\n",
    "перехода к tf\\*idf не всегда будет таким - если вы наблюдаете какое-то явление на одном датасете, не надо сразу же его обобщать на любые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f1 score: 0.852859955417\n"
     ]
    }
   ],
   "source": [
    "print('Mean f1 score:', test_classifier(\n",
    "        LogisticRegression(), TfidfVectorizer().fit_transform(texts), y, N_SPLITS, SCORING))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10\\*\n",
    "Попробуйте получить как можно более высокое качество на кросс-валидации. Напишите, что пробовали и какое качество получилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search для разных комбинаций признаков и классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from tools import ExtendedModel, ClfTester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FEATURES = {\n",
    "    'Tf*idf': ExtendedModel(TfidfVectorizer()),\n",
    "    'Token counts' : ExtendedModel(CountVectorizer()),\n",
    "    'Tf*idf & token counts': ExtendedModel(FeatureUnion([\n",
    "        ('Tf*idf', TfidfVectorizer()),\n",
    "        ('Token counts', CountVectorizer())\n",
    "    ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CLASSIFIERS = {\n",
    "    'Logistic Regression' : ExtendedModel( \n",
    "        LogisticRegression(), \n",
    "        {\n",
    "            'penalty': ('l1', 'l2'), \n",
    "            'C': [0.01, 0.1, 0.5, 1, 5, 10, 100, 200, 500, 1000, 10000, 15000, 20000, 100000]\n",
    "        }\n",
    "    ),\n",
    "    'Naive Bayes': ExtendedModel(\n",
    "        MultinomialNB(),\n",
    "        {\n",
    "            'alpha': [10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
    "        }\n",
    "    ),\n",
    "    'Linear SVM' : ExtendedModel(\n",
    "        LinearSVC(),\n",
    "        {\n",
    "            'C': [0.01, 0.1, 0.5, 1, 5, 10, 100, 200, 500, 1000, 10000, 15000, 20000, 100000]\n",
    "        }\n",
    "    ),\n",
    "    'Linear SVM & Features selection' : ExtendedModel(\n",
    "        Pipeline([\n",
    "            ('K_best', SelectKBest(chi2, k=500)), \n",
    "            ('Linear_SVM', LinearSVC())\n",
    "        ]),\n",
    "        {\n",
    "            'K_best__k': [100, 250, 500, 1000, 2000, 5000],\n",
    "            'Linear_SVM__C': [0.01, 0.1, 0.5, 1, 5, 10, 100, 200, 500, 1000, 10000, 15000, 20000, 100000]\n",
    "        }\n",
    "    )  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best model ---\n",
      "Tf*idf + Linear SVM with score 0.9512 and params:\n",
      "\tClassifier__C: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tester = ClfTester(FEATURES, CLASSIFIERS, SCORING, N_SPLITS)\n",
    "df_test_scores, df_best_estimators = clf_tester.test(texts, y, show_time_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_1141d688_0976_11e7_812a_a434d9c8df74row2_col1 {\n",
       "            \n",
       "                background-color:  yellow;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_1141d688_0976_11e7_812a_a434d9c8df74\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th class=\"blank\">\n",
       "                \n",
       "                <th class=\"col_heading level0 col0\">Naive Bayes\n",
       "                \n",
       "                <th class=\"col_heading level0 col1\">Linear SVM\n",
       "                \n",
       "                <th class=\"col_heading level0 col2\">Logistic Regression\n",
       "                \n",
       "                <th class=\"col_heading level0 col3\">Linear SVM & Features selection\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_1141d688_0976_11e7_812a_a434d9c8df74\" class=\"row_heading level3 row0\">\n",
       "                    Tf*idf & token counts\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row0_col0\" class=\"data row0 col0\">\n",
       "                    0.9493\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row0_col1\" class=\"data row0 col1\">\n",
       "                    0.944126\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row0_col2\" class=\"data row0 col2\">\n",
       "                    0.943542\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row0_col3\" class=\"data row0 col3\">\n",
       "                    0.941135\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_1141d688_0976_11e7_812a_a434d9c8df74\" class=\"row_heading level3 row1\">\n",
       "                    Token counts\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row1_col0\" class=\"data row1 col0\">\n",
       "                    0.950441\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row1_col1\" class=\"data row1 col1\">\n",
       "                    0.942705\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row1_col2\" class=\"data row1 col2\">\n",
       "                    0.943444\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row1_col3\" class=\"data row1 col3\">\n",
       "                    0.941884\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_1141d688_0976_11e7_812a_a434d9c8df74\" class=\"row_heading level3 row2\">\n",
       "                    Tf*idf\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row2_col0\" class=\"data row2 col0\">\n",
       "                    0.947705\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row2_col1\" class=\"data row2 col1\">\n",
       "                    0.951219\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row2_col2\" class=\"data row2 col2\">\n",
       "                    0.948382\n",
       "                \n",
       "                <td id=\"T_1141d688_0976_11e7_812a_a434d9c8df74row2_col3\" class=\"data row2 col3\">\n",
       "                    0.946775\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x2007598e940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scores.style.highlight_max(axis=None, subset=pd.IndexSlice[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С фильтрацией стоп слов из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURES = {\n",
    "    'Tf*idf': ExtendedModel(TfidfVectorizer(stop_words='english')),\n",
    "    'Token counts' : ExtendedModel(CountVectorizer(stop_words='english')),\n",
    "    'Tf*idf & token counts': ExtendedModel(FeatureUnion([\n",
    "        ('Tf*idf', TfidfVectorizer(stop_words='english')),\n",
    "        ('Token counts', CountVectorizer(stop_words='english'))\n",
    "    ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best model ---\n",
      "Tf*idf + Linear SVM with score 0.9468 and params:\n",
      "\tClassifier__C: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tester = ClfTester(FEATURES, CLASSIFIERS, SCORING, N_SPLITS)\n",
    "df_test_scores, df_best_estimators = clf_tester.test(texts, y, show_time_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_0766b1a8_0978_11e7_9299_a434d9c8df74row2_col1 {\n",
       "            \n",
       "                background-color:  yellow;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th class=\"blank\">\n",
       "                \n",
       "                <th class=\"col_heading level0 col0\">Naive Bayes\n",
       "                \n",
       "                <th class=\"col_heading level0 col1\">Linear SVM\n",
       "                \n",
       "                <th class=\"col_heading level0 col2\">Logistic Regression\n",
       "                \n",
       "                <th class=\"col_heading level0 col3\">Linear SVM & Features selection\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74\" class=\"row_heading level3 row0\">\n",
       "                    Tf*idf & token counts\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row0_col0\" class=\"data row0 col0\">\n",
       "                    0.935987\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row0_col1\" class=\"data row0 col1\">\n",
       "                    0.936799\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row0_col2\" class=\"data row0 col2\">\n",
       "                    0.936089\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row0_col3\" class=\"data row0 col3\">\n",
       "                    0.935648\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74\" class=\"row_heading level3 row1\">\n",
       "                    Token counts\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row1_col0\" class=\"data row1 col0\">\n",
       "                    0.945101\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row1_col1\" class=\"data row1 col1\">\n",
       "                    0.935291\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row1_col2\" class=\"data row1 col2\">\n",
       "                    0.936223\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row1_col3\" class=\"data row1 col3\">\n",
       "                    0.935074\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74\" class=\"row_heading level3 row2\">\n",
       "                    Tf*idf\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row2_col0\" class=\"data row2 col0\">\n",
       "                    0.94392\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row2_col1\" class=\"data row2 col1\">\n",
       "                    0.946819\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row2_col2\" class=\"data row2 col2\">\n",
       "                    0.944592\n",
       "                \n",
       "                <td id=\"T_0766b1a8_0978_11e7_9299_a434d9c8df74row2_col3\" class=\"data row2 col3\">\n",
       "                    0.943056\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x20075b9df28>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scores.style.highlight_max(axis=None, subset=pd.IndexSlice[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С фильтрацией стоп слов из nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NLTK_STOP_WORDS = list(stopwords.words('english'))\n",
    "\n",
    "FEATURES = {\n",
    "    'Tf*idf': ExtendedModel(TfidfVectorizer(stop_words=NLTK_STOP_WORDS)),\n",
    "    'Token counts' : ExtendedModel(CountVectorizer(stop_words=NLTK_STOP_WORDS)),\n",
    "    'Tf*idf & token counts': ExtendedModel(FeatureUnion([\n",
    "        ('Tf*idf', TfidfVectorizer(stop_words=NLTK_STOP_WORDS)),\n",
    "        ('Token counts', CountVectorizer(stop_words=NLTK_STOP_WORDS))\n",
    "    ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best model ---\n",
      "Tf*idf + Logistic Regression with score 0.9462 and params:\n",
      "\tClassifier__penalty: l2\n",
      "\tClassifier__C: 100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tester = ClfTester(FEATURES, CLASSIFIERS, SCORING, N_SPLITS)\n",
    "df_test_scores, df_best_estimators = clf_tester.test(texts, y, show_time_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_ee4e1626_0979_11e7_ac88_a434d9c8df74row2_col2 {\n",
       "            \n",
       "                background-color:  yellow;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th class=\"blank\">\n",
       "                \n",
       "                <th class=\"col_heading level0 col0\">Naive Bayes\n",
       "                \n",
       "                <th class=\"col_heading level0 col1\">Linear SVM\n",
       "                \n",
       "                <th class=\"col_heading level0 col2\">Logistic Regression\n",
       "                \n",
       "                <th class=\"col_heading level0 col3\">Linear SVM & Features selection\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74\" class=\"row_heading level3 row0\">\n",
       "                    Tf*idf & token counts\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row0_col0\" class=\"data row0 col0\">\n",
       "                    0.936646\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row0_col1\" class=\"data row0 col1\">\n",
       "                    0.943353\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row0_col2\" class=\"data row0 col2\">\n",
       "                    0.942739\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row0_col3\" class=\"data row0 col3\">\n",
       "                    0.938066\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74\" class=\"row_heading level3 row1\">\n",
       "                    Token counts\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row1_col0\" class=\"data row1 col0\">\n",
       "                    0.943827\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row1_col1\" class=\"data row1 col1\">\n",
       "                    0.940972\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row1_col2\" class=\"data row1 col2\">\n",
       "                    0.942665\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row1_col3\" class=\"data row1 col3\">\n",
       "                    0.939525\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74\" class=\"row_heading level3 row2\">\n",
       "                    Tf*idf\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row2_col0\" class=\"data row2 col0\">\n",
       "                    0.942495\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row2_col1\" class=\"data row2 col1\">\n",
       "                    0.94599\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row2_col2\" class=\"data row2 col2\">\n",
       "                    0.946157\n",
       "                \n",
       "                <td id=\"T_ee4e1626_0979_11e7_ac88_a434d9c8df74row2_col3\" class=\"data row2 col3\">\n",
       "                    0.942497\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x2007595e438>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scores.style.highlight_max(axis=None, subset=pd.IndexSlice[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С токенизацией слов из nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nltk_tokenize(texts_raw):\n",
    "    new_texts = []\n",
    "    for text in texts_raw:\n",
    "        tokens = word_tokenize(text)\n",
    "        new_texts.append(' '.join(tokens))\n",
    "    return new_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_nltk_tokens = nltk_tokenize(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FEATURES = {\n",
    "    'Tf*idf': ExtendedModel(TfidfVectorizer(analyzer=str.split)),\n",
    "    'Token counts' : ExtendedModel(CountVectorizer(analyzer=str.split)),\n",
    "    'Tf*idf & token counts': ExtendedModel(FeatureUnion([\n",
    "        ('Tf*idf', TfidfVectorizer(analyzer=str.split)),\n",
    "        ('Token counts', CountVectorizer(analyzer=str.split))\n",
    "    ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best model ---\n",
      "Token counts + Naive Bayes with score 0.9546 and params:\n",
      "\tClassifier__alpha: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tester = ClfTester(FEATURES, CLASSIFIERS, SCORING, N_SPLITS)\n",
    "df_test_scores, df_best_estimators = clf_tester.test(texts_nltk_tokens, y, show_time_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_063b2866_097c_11e7_920e_a434d9c8df74row1_col0 {\n",
       "            \n",
       "                background-color:  yellow;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_063b2866_097c_11e7_920e_a434d9c8df74\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th class=\"blank\">\n",
       "                \n",
       "                <th class=\"col_heading level0 col0\">Naive Bayes\n",
       "                \n",
       "                <th class=\"col_heading level0 col1\">Linear SVM\n",
       "                \n",
       "                <th class=\"col_heading level0 col2\">Logistic Regression\n",
       "                \n",
       "                <th class=\"col_heading level0 col3\">Linear SVM & Features selection\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_063b2866_097c_11e7_920e_a434d9c8df74\" class=\"row_heading level3 row0\">\n",
       "                    Tf*idf & token counts\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row0_col0\" class=\"data row0 col0\">\n",
       "                    0.950814\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row0_col1\" class=\"data row0 col1\">\n",
       "                    0.933681\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row0_col2\" class=\"data row0 col2\">\n",
       "                    0.940512\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row0_col3\" class=\"data row0 col3\">\n",
       "                    0.932732\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_063b2866_097c_11e7_920e_a434d9c8df74\" class=\"row_heading level3 row1\">\n",
       "                    Token counts\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row1_col0\" class=\"data row1 col0\">\n",
       "                    0.954605\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row1_col1\" class=\"data row1 col1\">\n",
       "                    0.933678\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row1_col2\" class=\"data row1 col2\">\n",
       "                    0.941239\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row1_col3\" class=\"data row1 col3\">\n",
       "                    0.936093\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_063b2866_097c_11e7_920e_a434d9c8df74\" class=\"row_heading level3 row2\">\n",
       "                    Tf*idf\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row2_col0\" class=\"data row2 col0\">\n",
       "                    0.944292\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row2_col1\" class=\"data row2 col1\">\n",
       "                    0.945687\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row2_col2\" class=\"data row2 col2\">\n",
       "                    0.943614\n",
       "                \n",
       "                <td id=\"T_063b2866_097c_11e7_920e_a434d9c8df74row2_col3\" class=\"data row2 col3\">\n",
       "                    0.946716\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x20076b6f7b8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scores.style.highlight_max(axis=None, subset=pd.IndexSlice[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С токенизацией и лемматизацией из nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nltk_lemmatize(texts_raw, with_stop_words=False):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    new_texts = []\n",
    "    for text in texts_raw:\n",
    "        tokens = [wnl.lemmatize(t) for t in word_tokenize(text)]\n",
    "        if with_stop_words:\n",
    "            tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
    "        new_texts.append(' '.join(tokens))\n",
    "    return new_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_nltk_lemms = nltk_lemmatize(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best model ---\n",
      "Token counts + Naive Bayes with score 0.952 and params:\n",
      "\tClassifier__alpha: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tester = ClfTester(FEATURES, CLASSIFIERS, SCORING, N_SPLITS)\n",
    "df_test_scores, df_best_estimators = clf_tester.test(texts_nltk_lemms, y, show_time_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_cca6b77e_097f_11e7_b512_a434d9c8df74row1_col0 {\n",
       "            \n",
       "                background-color:  yellow;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th class=\"blank\">\n",
       "                \n",
       "                <th class=\"col_heading level0 col0\">Naive Bayes\n",
       "                \n",
       "                <th class=\"col_heading level0 col1\">Linear SVM\n",
       "                \n",
       "                <th class=\"col_heading level0 col2\">Logistic Regression\n",
       "                \n",
       "                <th class=\"col_heading level0 col3\">Linear SVM & Features selection\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74\" class=\"row_heading level3 row0\">\n",
       "                    Tf*idf & token counts\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row0_col0\" class=\"data row0 col0\">\n",
       "                    0.947687\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row0_col1\" class=\"data row0 col1\">\n",
       "                    0.936076\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row0_col2\" class=\"data row0 col2\">\n",
       "                    0.937617\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row0_col3\" class=\"data row0 col3\">\n",
       "                    0.935516\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74\" class=\"row_heading level3 row1\">\n",
       "                    Token counts\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row1_col0\" class=\"data row1 col0\">\n",
       "                    0.95197\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row1_col1\" class=\"data row1 col1\">\n",
       "                    0.934424\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row1_col2\" class=\"data row1 col2\">\n",
       "                    0.937818\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row1_col3\" class=\"data row1 col3\">\n",
       "                    0.934803\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74\" class=\"row_heading level3 row2\">\n",
       "                    Tf*idf\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row2_col0\" class=\"data row2 col0\">\n",
       "                    0.945579\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row2_col1\" class=\"data row2 col1\">\n",
       "                    0.948382\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row2_col2\" class=\"data row2 col2\">\n",
       "                    0.945091\n",
       "                \n",
       "                <td id=\"T_cca6b77e_097f_11e7_b512_a434d9c8df74row2_col3\" class=\"data row2 col3\">\n",
       "                    0.94749\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x2007baae780>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scores.style.highlight_max(axis=None, subset=pd.IndexSlice[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С токенизацией и стеммингом из nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nltk_stem(texts_raw, with_stop_words=False):\n",
    "    ps = PorterStemmer()\n",
    "    new_texts = []\n",
    "    for text in texts_raw:\n",
    "        tokens = [ps.stem(t) for t in word_tokenize(text)]\n",
    "        if with_stop_words:\n",
    "            tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
    "        new_texts.append(' '.join(tokens))\n",
    "    return new_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_nltk_stems = nltk_stem(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best model ---\n",
      "Token counts + Naive Bayes with score 0.9503 and params:\n",
      "\tClassifier__alpha: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tester = ClfTester(FEATURES, CLASSIFIERS, SCORING, N_SPLITS)\n",
    "df_test_scores, df_best_estimators = clf_tester.test(texts_nltk_stems, y, show_time_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row1_col0 {\n",
       "            \n",
       "                background-color:  yellow;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th class=\"blank\">\n",
       "                \n",
       "                <th class=\"col_heading level0 col0\">Naive Bayes\n",
       "                \n",
       "                <th class=\"col_heading level0 col1\">Linear SVM\n",
       "                \n",
       "                <th class=\"col_heading level0 col2\">Logistic Regression\n",
       "                \n",
       "                <th class=\"col_heading level0 col3\">Linear SVM & Features selection\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74\" class=\"row_heading level3 row0\">\n",
       "                    Tf*idf & token counts\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row0_col0\" class=\"data row0 col0\">\n",
       "                    0.947597\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row0_col1\" class=\"data row0 col1\">\n",
       "                    0.942373\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row0_col2\" class=\"data row0 col2\">\n",
       "                    0.93979\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row0_col3\" class=\"data row0 col3\">\n",
       "                    0.937241\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74\" class=\"row_heading level3 row1\">\n",
       "                    Token counts\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row1_col0\" class=\"data row1 col0\">\n",
       "                    0.950256\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row1_col1\" class=\"data row1 col1\">\n",
       "                    0.940369\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row1_col2\" class=\"data row1 col2\">\n",
       "                    0.938282\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row1_col3\" class=\"data row1 col3\">\n",
       "                    0.93997\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74\" class=\"row_heading level3 row2\">\n",
       "                    Tf*idf\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row2_col0\" class=\"data row2 col0\">\n",
       "                    0.944873\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row2_col1\" class=\"data row2 col1\">\n",
       "                    0.950093\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row2_col2\" class=\"data row2 col2\">\n",
       "                    0.948003\n",
       "                \n",
       "                <td id=\"T_a19ff28c_0982_11e7_8fbd_a434d9c8df74row2_col3\" class=\"data row2 col3\">\n",
       "                    0.948898\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x20000926400>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scores.style.highlight_max(axis=None, subset=pd.IndexSlice[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С токенизацией, стеммингом и стоп словами из nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts_nltk_stems_stop_words = nltk_stem(texts, with_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best model ---\n",
      "Token counts + Naive Bayes with score 0.9491 and params:\n",
      "\tClassifier__alpha: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tester = ClfTester(FEATURES, CLASSIFIERS, SCORING, N_SPLITS)\n",
    "df_test_scores, df_best_estimators = clf_tester.test(texts_nltk_stems_stop_words, y, show_time_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_24c7ab14_0984_11e7_9396_a434d9c8df74row1_col0 {\n",
       "            \n",
       "                background-color:  yellow;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th class=\"blank\">\n",
       "                \n",
       "                <th class=\"col_heading level0 col0\">Naive Bayes\n",
       "                \n",
       "                <th class=\"col_heading level0 col1\">Linear SVM\n",
       "                \n",
       "                <th class=\"col_heading level0 col2\">Logistic Regression\n",
       "                \n",
       "                <th class=\"col_heading level0 col3\">Linear SVM & Features selection\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74\" class=\"row_heading level3 row0\">\n",
       "                    Tf*idf & token counts\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row0_col0\" class=\"data row0 col0\">\n",
       "                    0.946164\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row0_col1\" class=\"data row0 col1\">\n",
       "                    0.936085\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row0_col2\" class=\"data row0 col2\">\n",
       "                    0.936776\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row0_col3\" class=\"data row0 col3\">\n",
       "                    0.93333\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74\" class=\"row_heading level3 row1\">\n",
       "                    Token counts\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row1_col0\" class=\"data row1 col0\">\n",
       "                    0.949107\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row1_col1\" class=\"data row1 col1\">\n",
       "                    0.933581\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row1_col2\" class=\"data row1 col2\">\n",
       "                    0.936776\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row1_col3\" class=\"data row1 col3\">\n",
       "                    0.934998\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74\" class=\"row_heading level3 row2\">\n",
       "                    Tf*idf\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row2_col0\" class=\"data row2 col0\">\n",
       "                    0.939651\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row2_col1\" class=\"data row2 col1\">\n",
       "                    0.939788\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row2_col2\" class=\"data row2 col2\">\n",
       "                    0.94021\n",
       "                \n",
       "                <td id=\"T_24c7ab14_0984_11e7_9396_a434d9c8df74row2_col3\" class=\"data row2 col3\">\n",
       "                    0.943243\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x20000926518>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scores.style.highlight_max(axis=None, subset=pd.IndexSlice[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С токенизацией, лемматизацией и стоп словами из nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_nltk_lemms = nltk_lemmatize(texts, with_stop_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best model ---\n",
      "Token counts + Naive Bayes with score 0.949 and params:\n",
      "\tClassifier__alpha: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tester = ClfTester(FEATURES, CLASSIFIERS, SCORING, N_SPLITS)\n",
    "df_test_scores, df_best_estimators = clf_tester.test(texts_nltk_lemms, y, show_time_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_2ca57026_0987_11e7_95a4_a434d9c8df74row1_col0 {\n",
       "            \n",
       "                background-color:  yellow;\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th class=\"blank\">\n",
       "                \n",
       "                <th class=\"col_heading level0 col0\">Naive Bayes\n",
       "                \n",
       "                <th class=\"col_heading level0 col1\">Linear SVM\n",
       "                \n",
       "                <th class=\"col_heading level0 col2\">Logistic Regression\n",
       "                \n",
       "                <th class=\"col_heading level0 col3\">Linear SVM & Features selection\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74\" class=\"row_heading level3 row0\">\n",
       "                    Tf*idf & token counts\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row0_col0\" class=\"data row0 col0\">\n",
       "                    0.94279\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row0_col1\" class=\"data row0 col1\">\n",
       "                    0.931685\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row0_col2\" class=\"data row0 col2\">\n",
       "                    0.933746\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row0_col3\" class=\"data row0 col3\">\n",
       "                    0.927901\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74\" class=\"row_heading level3 row1\">\n",
       "                    Token counts\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row1_col0\" class=\"data row1 col0\">\n",
       "                    0.948973\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row1_col1\" class=\"data row1 col1\">\n",
       "                    0.931518\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row1_col2\" class=\"data row1 col2\">\n",
       "                    0.932193\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row1_col3\" class=\"data row1 col3\">\n",
       "                    0.928176\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74\" class=\"row_heading level3 row2\">\n",
       "                    Tf*idf\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row2_col0\" class=\"data row2 col0\">\n",
       "                    0.940385\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row2_col1\" class=\"data row2 col1\">\n",
       "                    0.936343\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row2_col2\" class=\"data row2 col2\">\n",
       "                    0.935644\n",
       "                \n",
       "                <td id=\"T_2ca57026_0987_11e7_95a4_a434d9c8df74row2_col3\" class=\"data row2 col3\">\n",
       "                    0.939432\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x2007ef65f98>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scores.style.highlight_max(axis=None, subset=pd.IndexSlice[:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11\n",
    "Какие наблюдения и выводы можно сделать из этого задания?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "На исследуемых данных лучше всего себя показал наивный байесовский классификатор на униграмах, полученнных с использованием токенизатора из библиотеки nltk.\n",
    "\n",
    "Общий вывод: на любых данных нужно пытаться проверить различные алгоритмы классификации в сочетании с различными методами предобработки данных и различными признаковыми пространствами, и не стоит рассчитывать, что на разных данных лучший метод будет один и тот же. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
